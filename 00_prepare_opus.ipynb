{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa0732-5451-45e9-a39e-c235657a3875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d024deb-3490-4de5-9413-94ffa9fabcf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_dir = '/media/xxxx/LaCie/data/opus_2018/'\n",
    "import os\n",
    "import re\n",
    "from itertools import chain\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict, deque\n",
    "import pandas as pd\n",
    "tls = {'el' : 'Greek', 'es' : 'Spanish', 'tr' : 'Turkish', 'fi' : 'Finnish', 'ar' : 'Arabic'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df5670-743c-45ce-b56e-8e671f14bd51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tail(filename, n=10):\n",
    "    'Return the last n lines of a file'\n",
    "    return deque(open(filename), n)\n",
    "        \n",
    "def get_metadata(fn):\n",
    "    language,genre = [],set()\n",
    "\n",
    "    lines = tail(fn,200000)\n",
    "    for li,line in enumerate(lines):\n",
    "        if re.match(r'\\s*\\<orig', line) != None: \n",
    "            #if li > 100: print(li, line)\n",
    "            language = re.sub(r'\\<.*?\\>', '', line.strip()).split(', ')\n",
    "            if genre != set(): break\n",
    "        if re.match(r'\\s*<genre', line) != None: \n",
    "            #if li > 100: print(li, line)\n",
    "            genre = set(map(lambda x : x.strip(), re.sub(r'\\<.*?\\>', '', line.strip()).strip('[]\\'').split(',')))\n",
    "            if language != []: break\n",
    "    return language, genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664257d4-59a9-48ee-8949-2d5226cc29db",
   "metadata": {},
   "source": [
    "## get all bitext mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f43ab4-82c3-4149-b45e-b7beca46f57d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_mappings = {}\n",
    "for tl in tls:\n",
    "    print(tl)\n",
    "    la,lb = sorted([tl,'en'])\n",
    "    la2lb, lb2la = {}, {}\n",
    "    try: fh = open('%s/%s-%s.txt/OpenSubtitles.%s-%s.ids' % (source_dir,la,lb,la,lb))\n",
    "    except: continue\n",
    "    for idx in fh:\n",
    "        ea,eb = idx.strip('\\n').split('\\t')[:2]\n",
    "        if ea not in la2lb:\n",
    "            la2lb[ea] = eb\n",
    "            lb2la[eb] = ea\n",
    "    movie_mappings[tl] = (la2lb,lb2la)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fbe7e4-4ee4-4592-86e9-c1b0ddc5f986",
   "metadata": {},
   "source": [
    "## get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4600797d-d99f-4e7b-a588-5c2b439956db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for tl in tls:\n",
    "    metadir = source_dir + tl + '/OpenSubtitles/xml/'\n",
    "    bldr = []\n",
    "    files = list(map(lambda f : f[:-3], movie_mappings[tl][tl > 'en']))\n",
    "    print(tl, len(files), datetime.now())\n",
    "    with Pool(12) as p:\n",
    "        metadata = p.map(get_metadata, (metadir + fn for fn in files))\n",
    "    pd.DataFrame([{'year':fn.split('/')[1], 'movie':fn.split('/')[2], 'version':fn.split('/')[3], 'languages':l, 'genres':g} \n",
    "                  for fn,(l,g) in zip(files, metadata)]).to_excel('./files/%s_metadata.xlsx' % tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86490d0f-fc42-465c-b5f2-058cba8c8dbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq_tls = {}\n",
    "for tl,tlx in tls.items():\n",
    "    print(tl,tlx)\n",
    "    df = pd.read_excel('./files/%s_metadata.xlsx' % tl)\n",
    "    dfx = df[df.languages.isin({\"['%s']\" % tlx, \"['English']\"})]\n",
    "    print(Counter(dfx['languages']))\n",
    "    if sum(dfx['languages'] == \"['%s']\" % tlx) >= 12:\n",
    "        freq_tls[tl] = tlx\n",
    "print(freq_tls)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3976f9a3-7d45-41b7-94ca-31e92772944f",
   "metadata": {},
   "source": [
    "## determine genre-matched pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94abd6f9-0eff-4d22-a3a5-b6421cdb1e63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for tl,tlx in freq_tls.items():\n",
    "    dfx = pd.read_excel('./files/%s_metadata.xlsx' % tl)\n",
    "    items_tl = {(r.year,r.movie,r.version):eval(r.genres) for i,r in dfx.iterrows() if r.languages == \"['%s']\" % tlx}\n",
    "    items_en = {(r.year,r.movie,r.version):eval(r.genres) for i,r in dfx.iterrows() if r.languages == \"['English']\"}\n",
    "    print(tl, len(items_tl))\n",
    "    #\n",
    "    builder, seen = [], set()\n",
    "    for i,((y,f,v),g) in enumerate(sorted(items_tl.items())):\n",
    "        if '%s/%s/%s/%s.gz' % (tl, y, f, v) not in movie_mappings[tl][int(tl > 'en')]: continue\n",
    "        if f in seen: continue\n",
    "        seen.add(f)\n",
    "        print(y,f,v,g)\n",
    "        #\n",
    "        best_match_score, builder_it = 0, None\n",
    "        for (yy,ff,vv),gg in sorted(filter(lambda k : isinstance(k[0][0],int) or k[0][0].isnumeric(), items_en.items()), key = lambda k : abs(int(k[0][0])-int(y))):\n",
    "            if '%s/%s/%s/%s.gz' % (tl, yy, ff, vv) not in movie_mappings[tl][int(tl > 'en')]: continue\n",
    "            #\n",
    "            print('\\t', yy,ff,vv, gg)\n",
    "            if g == gg:\n",
    "                print('\\t\\tmax found')\n",
    "                builder_it = {'tl_y' : y, 'tl_f':f, 'tl_v':v, 'tl_g' : g, 'en_y':yy, 'en_f':ff, 'en_v':vv, 'en_g':gg}\n",
    "                break\n",
    "            elif len(g&gg)/len(g|gg) > best_match_score:\n",
    "                best_match_score =  len(g&gg)/len(g|gg) \n",
    "                print('\\t\\tbetter match found: %.2f' % best_match_score)\n",
    "                builder_it = {'tl_y' : y, 'tl_f':f, 'tl_v':v, 'tl_g':g, 'en_y':yy, 'en_f':ff, 'en_v':vv, 'en_g':gg}\n",
    "            if abs(int(yy)-int(y)) > 10: break\n",
    "        if builder_it != None:\n",
    "            builder.append(builder_it)\n",
    "    pd.DataFrame(builder).to_excel('./files/%s_matched_files.xlsx' % tl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c66b5-9038-4c7a-9652-930f8c35a717",
   "metadata": {},
   "source": [
    "## write bitexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01df244b-0082-417a-8def-20922f3919ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for tl in freq_tls:\n",
    "    la,lb = sorted([tl,'en'])\n",
    "    metadata = []\n",
    "    #\n",
    "    dfx = pd.read_excel('./files/%s_matched_files.xlsx' % tl)\n",
    "    items_tl = {(str(r.tl_y),str(r.tl_f),r.tl_v) for i,r in dfx.iterrows()}\n",
    "    items_en = {(str(r.en_y),str(r.en_f),r.en_v) for i,r in dfx.iterrows()}\n",
    "    la,lb = sorted([tl,'en'])\n",
    "    #\n",
    "    with open('./generated/opus_bitexts/%s_bitext.txt' % tl,'w') as fout:\n",
    "        for i,(idx,ra,rb) in enumerate(zip(open('%s/%s-%s.txt/OpenSubtitles.%s-%s.ids' % (source_dir,la,lb,la,lb)),\n",
    "                                   open('%s/%s-%s.txt/OpenSubtitles.%s-%s.%s' % (source_dir,la,lb,la,lb,tl)),\n",
    "                                   open('%s/%s-%s.txt/OpenSubtitles.%s-%s.%s' % (source_dir,la,lb,la,lb,'en')))):\n",
    "            e1,e2 = idx.strip('\\n').split('\\t')[:2]\n",
    "            if tl > 'en': e1,e2 = e2,e1\n",
    "            orig = 'orig' if tuple(e1[3:-3].split('/')) in items_tl else ('translated' if tuple(e1[3:-3].split('/')) in items_en else None)\n",
    "            if orig != None:\n",
    "                metadata.append({k:v for k,v in zip(['la','lb','ra','rb'], idx.strip('\\n').split('\\t'))} | {'original' : orig })\n",
    "                fout.write(ra.strip('\\n') + ' ||| ' + rb.strip('\\n') + '\\n')\n",
    "                if len(metadata) % 2500 == 0: print(tl, len(metadata), e1, datetime.now())\n",
    "    #\n",
    "    pd.DataFrame(metadata).to_excel('./generated/opus_bitexts/%s_bitext_metadata.xlsx' % tl)\n",
    "    print(Counter([m['original'] for m in metadata]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4101c42-b273-465f-9809-8943f7e3d7b3",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## spacy english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08b7f02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b60411f-1de4-4c7c-bcd0-7cc8f1221732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for lg in freq_tls:\n",
    "    new_bit = []\n",
    "    for li,l in enumerate(open('./generated/opus_bitexts/%s_bitext.txt' % lg).readlines()):\n",
    "        spacied = ['/'.join(map(lambda e : str(e).replace('/','#').replace(' ', '#'), [w.text, w.i, w.lemma_, w.pos_, w.tag_, w.dep_, w.head.i]))\n",
    "                   for w in nlp(l.strip('\\n').split(' ||| ')[1])]\n",
    "        new_bit.append((l.strip('\\n').split(' ||| ')[0], ' '.join(spacied)))\n",
    "        if li % 10000 == 0: print(lg, li, new_bit[-1])\n",
    "    with open('./generated/opus_bitexts/%s.spc' % lg, 'w') as fout:\n",
    "        fout.write('\\n'.join('%s ||| %s' % ln for ln in new_bit))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
